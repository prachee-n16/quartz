{"/":{"title":"Prachee Nanda","content":"Hi there üëã! Welcome to my digital garden, a collection of notes on topics that have captured my interest and curiosity. Inspired by the Zettelkasten approach, my aim is to expand my knowledge and discover new insights.\n\nThis notebook will keep on changing and improving over time, so don't expect it to be perfect yet. Some pages might still be a work in progress.\n- [[notes/Projects|Projects]]\n- [[notes/Areas|Areas]]\n- [[notes/Resources|Resources]]\n- [[notes/Archives|Archives]]\n\nWhile I'm still playing around with how I want to build my `second brain`, here are some basic principles I follow!\n\nMy process for generating content for the second brain is based on the CODE system. This involves 4 steps: **C**apture, **O**rganize, **D**istill and **E**xpress. In brief,\n- Capture: The idea is to capture information that is interesting, relevant or personal to me.\n- Organize: I plan to write on a variety of topics, so organizing all these notes is key! The basic rule of thumb is PARA, which stands for **PROJECTS**, **AREAS**, **RESOURCES**, **ARCHIVE**. I'm also looking into tagging all notes as an alternative form of finding content in the future.\n- Distill: Condensing information into the key points. This would be more critical when I am taking course notes or self-learning a topic.\n- Express: With Obsidian, I want to use the Graph view to make connections across the various notes.\n","lastmodified":"2024-03-14T01:23:04.270879219Z","tags":[]},"/notes/Alpha-beta-Pruning":{"title":"Alpha-beta Pruning","content":"Search algorithm that decreases the number of gate states to evaluate in [[Braitenberg vehicles|Braitenberg vehicles]] in the game tree.\n- Stopping condition: It does not evaluate further when it realizes that there is already an existing better alternative.\nNote: It's the same final output as Minimax, just a more efficient way of going about it.\n\n##### High-level Overview\nLike minimax,\n- Each node in the game tree represents a possible situation in the game\n- Each endgame situation is assigned a value\n\nAs we go through the game tree, we keep track of two values,\n- Alpha: Minimum value the max player can get, initially set to -‚àû\n- Beta: Maximum value the min player can get, initially set to +‚àû","lastmodified":"2024-03-14T01:23:04.270879219Z","tags":["Areas","#to-complete"]},"/notes/Archives":{"title":"üóÑÔ∏è Archives","content":"","lastmodified":"2024-03-14T01:23:04.270879219Z","tags":["Archives","to-complete"]},"/notes/Areas":{"title":"üî≠ Areas","content":"This space is designed to store important metadata regarding files in this section. \n\nArtificial Intelligence\n- [[Alpha-beta Pruning]]\n- [[Assumptions of Linear Regression]]\n- [[Multiple Linear Programming]]\n- [[Ethics in AI]]\n\nComputer Science\n- Operating System\n\t- [[Introduction to OS|Introduction to OS]]\n\t- [[File System]]\n\t- [[Interrupts and System Calls]]\n- [[Elementary Graph Algorithms]]\n- [[Programming Paradigm]]\n- [[Data Formats]]\n- [[Socket Programming]]\n- [[Image Feature Vector]]\n- [[Image Formats \u0026 Compression Comparision]]\n\nMathematics\n-  [[First-Order Logic]]\n\nGeneral\n- [[Zettelkasten]]\n","lastmodified":"2024-03-14T01:23:04.270879219Z","tags":["Areas","to-complete"]},"/notes/Assumptions-of-Linear-Regression":{"title":"Assumptions of Linear Regression","content":"Anscombe's Quartet - A group of four data sets with nearly identical descriptive statistics, yet different distributions and graphs. These are prime examples of why it's important to be selective on when to use linear regression!\n\n![](https://matplotlib.org/stable/_images/sphx_glr_anscombe_001.png)\n\n  \nThe assumptions we make about a dataset when choosing to apply linear regression:\n1. Linearity\n\tThere is a linear relationship between y and x, such that it can be modelled by the equation $y = mx+b$\n2. Homoscedasticity\n\tEqual Variance: There shouldn't be a cone type shape (increasing or decreasing) because it shows a dependance on dependent variable\n3. Multivariate Normality\n\tNormality of error distribution. As we look at data points around regression line, we want to see a normal distribution.\n4. Independence of observations, which includes no autocorrelation\n\tThere really should be no pattern to data, as this indicates each variable is not truly independent\n5. Lack of multicollinearity\n\tWhenever an independent variable is highly correlated with one or more of the other independent variables in a multiple regression equation - it undermines the statistical significance of an independent variable.\n...and an extra check that there aren't outliers skewing the data.","lastmodified":"2024-03-14T01:23:04.270879219Z","tags":["Areas","completed"]},"/notes/Avro":{"title":"Avro","content":"- Each record has a header that describes the structure of data it contains\n\t- Data is stored as binary information, and information in header is used to parse data and extract fields\n\t- Good format for compressing data, minimize storage and network bandwidth requirements\n\n**Evolution of data formats to Avro:**\nWith [[notes/Delimited Text Files|Delimited Text Files]], there are some disadvantages:\n- Data types need to be inferred, and not a guarantee\n- Parsing is tricky if data has commas\n- Column names might not be there\n\nRelational Databases: add types (fixing the first disadvantage):\n```\nCREATE TABLE fruits {\n\tid      integer PRIMARY KEY,\n\tname    varchar(20)\n}\n```\nHowever, this data is flat i.e. stored in plain text format and this data is stored in databases, where this definition might be different across databases.\n\n[[JSON]]: a widely accepted format that can take any form and easily shared over network. \n- Still, there's no type definitions. \n- Repeated keys leads to bigger JSON objects\n- No comments, metadata, documentation\n\nWith Avro, the advantages are:\n- Data is fully typed, schema is defined, and compressed automatically\n- Documentation is embedded into schema\n- Safe schema evolution\n\nSimilar to [[Parquet]], [[ORC]]","lastmodified":"2024-03-14T01:23:04.270879219Z","tags":["DataFundamentals","Areas","completed"]},"/notes/BLOB":{"title":"BLOB","content":"*Binary Large Object*\n- All files are stored as binary data\n\t- Commonly used to store images, video, audio and app-specific documents\n","lastmodified":"2024-03-14T01:23:04.270879219Z","tags":["DataFundamentals","Areas","#to-complete"]},"/notes/Braitenberg-vehicles":{"title":"Braitenberg vehicles","content":"Source: [Braitenberg Vehicle Wiki](https://en.wikipedia.org/wiki/Braitenberg_vehicle)\n\nThis was a thought experiment by Valentino Braitenberg.\n\nIn the simplest form of this experiment, a *Braitenberg vehicle* is a machine with a light sensor and a motor. The two are connected such that the motor turns on when the sensor detects light, and turns off when the sensor detects no light. So, this gives the effect that the vehicle seeks out light sources.\n\nHence, the sensor-motor wiring gives rise to interesting effects. Note, this seems intelligent (to be moving towards light source) but is completely decentralized.\n\n**Agents**\n- System that processes data, produces an output from input\n- Reflex agent - reacts to input, Memory agent - reacts to maybe past decisions","lastmodified":"2024-03-14T01:23:04.270879219Z","tags":["Areas","completed"]},"/notes/Collectors-Fallacy":{"title":"Collector's Fallacy","content":"To know about something is not the same as knowing something.\n\nThe idea here is that we like collecting information, hoping that it will be useful down the way. However, this mindless collection of ideas is creating a fake sense of knowledge. We know the information but we don't actually break it down into our own ideas and words. \n\nAm I guilty of this? Possibly~ I noted that my review sheets during exams was helpful because I was taking the content and writing them down as possible questions. In a way, I'm breaking this down into how I actually was understanding the content. There is some deliberation in this method!\n\nA good way to get out of this is: knowledge cycle!\n- Read any text for an hour, and when the time limit is over, look back and see what you have learnt!\n","lastmodified":"2024-03-14T01:23:04.270879219Z","tags":["NoteTaking","ZettelkastenGuide","Areas","completed"]},"/notes/Data-Formats":{"title":"Data Formats","content":"\u003e [!tip] TLDR\n\u003e - Data can be structured, unstructured or aggregated\n\u003e\t- Structured data is data that can be modelled. For example, text, numbers can fit into data tables\n\u003e\t- Unstructured data is data that is hard to model due it's size or nature. So, audio, video or large text documents fit the bill\n\u003e\t- Aggregated data is when multiple data sources are combined into one set. This is then used to create a statistical report that makes inferences about the population.\n\nStructured data is data that adheres to a schema, most commonly, tabular representation\n- Columns represent the attributes of entity, Rows represent each instance of data entity\n- Relational model: Use key values to refer to entities in different databases\n\nSemi-structured data is information with some structure, but has variations between instances. [[JSON]] documents allows for representing this type of data (it's flexible)\n\nUnstructured data that has no structure.\n\nFormat is import for [[Data Stores|storing data]], retrieving for analysis and reporting data.","lastmodified":"2024-03-14T01:23:04.270879219Z","tags":["Areas","DataFundamentals","completed"]},"/notes/Data-Stores":{"title":"Data Stores","content":"There are two broad categories of data store:\n- file stores\n- databases\n# File Stores\n*Store data in files*\n\nThe file format used to store data depends on:\n1. [[notes/Data Formats|Type of data to be stored]]\n2. Application/Services that need to interact (i.e. perform CRUD operations) with data\n3. Purpose of storage: Does this need to be readable by humans, or optimized for efficient storage and processing\n## Common File Formats\n- [[Delimited Text Files]]\n- [[JSON]]\n- [[XML]]\n- [[BLOB]]\n- [[Avro]]\n- [[ORC]]\n- [[Parquet]]\n# Databases\n*Central system where data is stored and searched through*\n- Relational Databases\n- Non-relational Databases","lastmodified":"2024-03-14T01:23:04.270879219Z","tags":["DataFundamentals","Areas","to-complete"]},"/notes/Delimited-Text-Files":{"title":"Delimited Text Files","content":"*Technology examples: CSV, TSV files*\n\n- Stored in plain text format with specific field delimiters and row terminators\n\t- In CSV (comma-separated values), field delimiters = comma and row terminators = new line\n\t\t- First line may contain title to columns\n\t- Also, TSV (tab-separated values) with only difference being field delimiters = tabs\n\t- Space-delimited where spaces and tabs are used to separate columns\n\t- Fixed-width data where each field has fixed number of characters\n\t\t- More detailed explanation here: https://www.softinterface.com/Convert-XLS/Features/Fixed-Width-Text-File-Definition.htm\n- Why use this?: human-readable format\n\n\n","lastmodified":"2024-03-14T01:23:04.270879219Z","tags":["DataFundamentals","Areas","completed"]},"/notes/Elementary-Graph-Algorithms":{"title":"Elementary Graph Algorithms.","content":"- A graph $G = (V, E)$ is composed of $V$, a set of vertices and $E \\in V \\times V$ \n- The two standard way of representing a graph is:\n\t- Adjacency List\n\t\t- Good idea when representing sparse graphs i.e. $|E| \u003c\u003c |V|^2$ where number of edges is a lot less than the possible connections between all vertices\n\t\t- Pros\n\t\t\t- Easy to transform into a weighted graph, given a weighted function\n\t\t\t- Amount of memory for both directed/undirected is $\\theta(V+E)$\n\t\t- Cons\n\t\t\t- No easy way to determine if an edge exists\n\t- Adjacency Matrix\n\t\t- Good idea when representing dense graphs i.e. $|E| \u003c |V|^2$ where number of edges is close to the most number of connections between all vertices\n\t\t- Pros\n\t\t\t- Easier to use then adjacency list, where undefined edges can be represented as 0, `null`, `undefined` etc.\n\t\t- Cons\n\t\t\t- Amount of memory for directed and undirected is $\\theta(V^2)$, can be optimized to lose diagonal if no self-loops\n\t\t\t\t- In undirected, we can lose half this space since $(u, v) = (v, u)$","lastmodified":"2024-03-14T01:23:04.270879219Z","tags":["Areas","to-complete"]},"/notes/Ethics-in-AI":{"title":"Ethics in AI","content":"\n**AI and Society**\n- The big question has always been¬†**will AI destroy jobs**?\n    - AI will replace the unpleasant or dangerous jobs, completing tasks with more efficiency and precision\n    - Rise of AI accelerates¬†_growth/consumption spiral_\n        - Companies want to lower prices, laying off workers to cut costs\n        - Lower prices is higher demand, so higher production (using more resources here)\n        - In modern countries, where population doesn't grow, individual person must consume more (marketing helps with this!)\n    - More people left unsatisfied (consuming goods they don't want, high unemployment etc)\n    - There needs to be an \"economy for the common good\" where we go for sustainability, rather than profit\n\n**Filter Bubbles**¬†The goal of content recommendation systems, especially those used in social media/newsfeeds, is to provide personalized searches. The unintended effect can be an¬†_intellectual isolation_¬†- you keep being offered curated results, but you find yourself in a bubble of only your own ideas.\n\n- How is this different from an epistemic bubble? In this situation, the user never gets the information by fault of the algorithm. Epistemic bubble is that the opposing view is simply left out.\n\n**Echo Chambers**¬†Stemming from filter bubbles, we see echo chambers: Users come across content that only amplifies \u0026 reinforces their beliefs. Essentially, it's confirmation bias.","lastmodified":"2024-03-14T01:23:04.270879219Z","tags":["Areas","to-complete"]},"/notes/File-Access-Mechanisms-in-Filesystems":{"title":"File Access Mechanisms in Filesystems","content":"Files usually have some permissions associated with them: \n- Read\n- Write\n- Execute\n- Append (write at the end of the file)\n- Delete\n- List (view the attributes of the file)\n\n**Access control**\n- permissions can be assigned for: Owner, Group, Everyone\n- Three basic permissions: R, W, Execute\n\t- permissions are represented by 10 bits where 1 indicates true, 0 indicates false\n- first bit is directory bit.\n\t- Next three are read, write, execute for the owner. \n\t- Then read, write, execute for the group. \n\t- Finally, read, write, execute for everyone.\n\nThe permissions can be shown in a human-readable format.\n- The character d is used to indicate a directory. \n- r to indicate read access. \n- w to indicate write access. \n- x to indicate execute access\n\n**File Locks**\n- Some OS supports file locks which can be exclusive or non-exclusive\n\t- When a file is locked by a process, other processes can't open that file (see a failure)\n\t- It also can not be deleted when it is being used by a program\n- Windows uses locking: any file open in an program can't be deleted but UNIX does not\n\t- as long as program remains open, retaining ref to file, it can still operate on file\nTo lock a file in Linux, the call for this is flock()\nA shared lock would be LOCK_SH, and to unlock the parameter is LOCK_UN\n- Non-exclusive file locks (also known as shared locks or read locks) allow multiple processes or threads to access a file simultaneously for reading purposes\n- Exclusive file locks (also known as write locks or exclusive locks) provide exclusive access to a file to the process or thread that holds the lock","lastmodified":"2024-03-14T01:23:04.270879219Z","tags":["OperatingSystems","Areas","completed"]},"/notes/File-System":{"title":"File System","content":"**File System**\nThe file system provides organization for the files through a directory structure + maintains metadata related to files.\n\nIn UNIX, \"everything is a file\"\n- TODO: Look into: https://tldp.org/LDP/sag/html/dev-fs.html\n- An area of disk is designates as belonging to a file, and file is just a logical unit to organize this.\n\nFiles have the following attributes:\n- Name\n- Identifier: numerical value that serves as a unique identifier for the file within the file system (find this for a file)\n\t- there is not much of a difference between this and name\n- Type\n\t- in most OS, any program can open arbitrary files and the extensions are just a suggestion. \n- Location\n- Size\n- Protection\n- Time, Date, User ID\n\nQNX (OS provided by Blackberry) - primarily used in embedded systems\n- files are maintained in a structure. Directories are really just like files, information about what files are where, and they are also being stored on disks\n\nSix basic file ops:\n1. Creating a file [Go to Section](#create)\n2. Writing a file [Go to Section](#write)\n3. Reading a file [Go to Section](#read)\n4. Reposition within a file [Go to section](#seek)\n5. Delete a file  [Go to section](#delete)\n6. Truncate a file  [Go to section](#delete)\n#### create\n(by extension write/read)\nfopen will call open on a file - When running Windows, it actually runs openFileEx() under the hood. We don't really need to care since it abstracts this from us. The UNIX system libraries use an integer instead of a FILE*.\n- FILE* is an access to the file apparently? access point to a file or an input/output stream rather than the file or stream itself\n\nIn addition to the filename as the first parameter, the function is called with the mode as the second parameter.\n- **\"r\" (Read)**: Opens a file for reading.\n- **\"w\" (Write)**: Opens a file for writing.\n- **\"a\" (Append)**: Opens a file for writing, but if the file exists, it appends data to the end rather than truncating it.\n- **\"r+\" (Read and Write)**: Opens a file for both reading and writing\n- **\"w+\" (Write and Read)**: Opens a file for both reading and writing\n- **\"a+\" (Append and Read)**: Opens a file for both reading and writing. If the file doesn't exist, it creates a new file. If it exists, it appends data to the end.\n- \"x\" (new to C): create a new file safely without risking the unintentional overwriting of an existing file\nIf you add b to the end, like `rb` then we are reading in binary mode. Mostly irrelevant.\n#### seek\n- Repositioning is also called a seek, done in C with the `fseek()` call which adjusts pointer for reading or writing\n- you can go to any arbit. character so it's actually kind of dangerous and we can not call this op if a file is opened for append\n- passing a negative number will move you backwards/\n#### delete\n- In C, a file is deleted with the remove() function because this simple program deletes whatever file is provided as the second argument.\nTruncating can only be done with the UNIX libraries using either truncate() or ftruncate().\n#### write\n- writing is easy because it works like printf, actual function call is just called `fprintf` \n#### read\n- Reading from a file involves the use of fscanf which is a mirror image of fprintf\n\nA directory is a symbol table that translates file name to directory entries. Typically support the below operations\n- search\n- list directory\n- navigate file system\n- add and remove and rename file\nTree-structured: there is a root directory, and every file in the system has a unique name when the name and path to it (from the root) are combined.\n\nFile systems may also support the sharing of files. There is one copy of the file but it has more than one name. In UNIX this is called a link and this is effectively a pointer to another file.\n- Symlinks, or symbolic links, are just references by file name.\n- Creating a hardlink is creating a pointer to the underlying file in the file system.\n- If a hardlink exists and the user deletes that file, the file still remains on disk until last hardlink is removed\n\nAlso: [[File Access Mechanisms in Filesystems]]","lastmodified":"2024-03-14T01:23:04.270879219Z","tags":["C","Areas","OperatingSystems","completed","ece252"]},"/notes/First-Order-Logic":{"title":"First-Order Logic","content":"G√∂del's Theorems i.e. [[G√∂del's Completeness Theorem]] and [[G√∂del's Incompleteness Theorem]] were important to AI.\n\nFrom the completeness theorem, automatic theorem provers were created - In the 1950s, the Logic Theorist was made to show computers could process numbers and symbols.\n- LISP and PROLOG: programming languages created to process symbolic structure\n\nIn the incompleteness theorem, we know that there are true statements which can not be proved. This shows the limits of using a logic-based system. Another limit is the Halting Problem i.e. there is no program that can decide whether a program runs in an infinite loop or not.","lastmodified":"2024-03-14T01:23:04.270879219Z","tags":["Areas","to-complete"]},"/notes/Function-Composition-in-Javascript":{"title":"Function Composition in JavaScript","content":"JavaScript is a multi-paradigm programming language - it has supports for several [[Programming Paradigm]], including [[Functional Programming]].\n\nFunction Piping vs. Composition\n- It's a matter of how functions are being executed: If functions are executed from left to right, that's a pipe while right to left is called compose\n\nNote: Functional Programming is about working with pure functions (functions with no side effects). However, that's not possible in real-life applications that deal with state and side-effects - that's where MONAD, a design pattern comes in. \n\nIn monadic composition, we add an extra requirement: It needs to explain how it got to the end result. Let's build a math expression\n```\n// The actual function attached with a description\nconst add6 = x =\u003e [x+5, '+6']\nconst multiply6 = x =\u003e [x*6, '*6']\n```","lastmodified":"2024-03-14T01:23:04.270879219Z","tags":["Areas","completed"]},"/notes/Functional-Programming":{"title":"Functional Programming","content":"\n*What is Functional Programming?* A [[Programming Paradigm]].\n\nThe main focus is on \"what are we trying to solve\", rather than \"how are we trying to solve\" - It's a declarative type of programming\n- A nice way to imagine this is when jump into a cab, we tell the driver where we want to go. We don't give him turn-by-turn instructions i.e. imperative approach.\nIt is based on \u003cins\u003eLambda Calculus\u003c/ins\u003e: \n- Lambda Calculus is about studying computations with functions, which can also be used to simulate Turing Machine\n\t- In this logic system, functions are anonymous. We do not give them explicit names. $square\\_sum(x,y) = x^2 + y^2$ rewritten as $(x,y) \\rightarrow x^2 + y^2$    \n\t- Uses function of a single input, so the above example can be reworked:  $(x,y) \\rightarrow x^2 + y^2$  to $x \\rightarrow (y \\rightarrow x^2 + y^2)$. This is also now an example of a [[Higher-Order Functions]]","lastmodified":"2024-03-14T01:23:04.270879219Z","tags":["Areas","to-complete"]},"/notes/Fundamentals-of-C":{"title":"Fundamentals of C","content":"\n**Overview of C**\n- It is a procedural language.\n\t- It has functions but it's not a functional programming language, unlike C++ which has object-oriented capabilities. \n- Header files are imported into a program using precompiler directive as follows:\n```cpp\n#include \u003cstdio.h\u003e\n#include \u003cstdlib.h\u003e\n\n/* \nIn C, there is no bool type and often, we use int 0/1 to denote true or false.\nAlternative, include below header file for bool type\n*/\n#include \u003cstdbool.h\u003e \n```\n- In old versions of C, two-passes were too time-taking so it's limited to one. This means functions can't be used before they are declared.\n\t- Alternative: Use a function prototype, promising an implementation exists below\n- Structs are a grouping of variables\n```\nstruct color {\n\tint r;\n\tint g;\n\tint b;\n\tint a;\n}\n\ntypedef struct color {\n\tint r;\n\tint g;\n\tint b;\n\tint a;\n} color_t;\n```\n\nHow to make an array of boxes in C++?\n```\nbox* boxes = new box[10]\n```\n\n... but this syntax changes in C as follows. Specifically, it needs details on memory allocation:\n```\nbox* boxes = malloc(10*sizeof(box))\n```\n\nThe idea is: I want you to allocate memory equal to `10 * sizeOf(1 box)`\n- Malloc is suitable when memory content initialization is not necessary, and the program is dealing with a single block of memory. \n- Calloc is useful when the program requires multiple blocks of memory, especially when handling arrays or structures that need to be initialized to zero.\n\nTo delete this object in C++, the syntax is `delete[] boxes;` while in C, it is,\n```\nfree(boxes)\n```\nHow does C realize how much memory to free? When memory is first allocated, the computer keeps track of it. Prior to the pointer of the object, it keeps information on the size of the block. Also, free(var) does not actually erase the memory so it needs to be set as nullptr or undefined in the right context.\n- Use after free is¬†**a vulnerability related to incorrect use of dynamic memory during program operation**.\n\nAssigning values in these arrays works like this:\n```\nboxes[0].height = 10;\nboxes[0].width = 10;\n\nboxes-\u003eheight = 10;\n```\n\nNote,\n```\n%% If we attempt to print an uninitialized memory block, the value is undefined %%\nprintf(\"%d\\n\", boxes[0].width)\n```\n*Calloc will help eliminate this issue!*\n\nThis line looks at boxes, which starts at 0 and will look at the next element `boxes[1]` and perform the change.\n```\n(boxes+1)-\u003eheight = 12\n```\nHence, equivalent to:\n```\nboxes[1].height = 12\n```\n\n**Notes on printing**\nIn C++, `std::cout \u003c\u003c boxes[0].width \u003c\u003c std::endl;` but the issue in C, is that `std::cout` does not exist despite the elegance. \n```\nprintf(\"%d\\n\", boxes[0].height)\n```\nThe newline character in C is done through special character `\\n`\nReview: Conversion Specifiers in https://man7.org/linux/man-pages/man3/printf.3.html\n\nWhen specifying main in C, \n```\nint main( int argc, char* argv[]) { ... }\n```\n\nIn C, a string a string of characters and ends in a null character. The parameters to main are:\n```\nchar* hello = \"hi\";\nprintf(\"%s %s\\n\", hello, argv[1])\n%% Take hello, and the first line argument from the command line and append it %%\n```\nNote, declarations of variables must be at the top of the file.\n\n```\n#include \"string.h\"\n\nconst char* hello = \"hi\";\nconst char* test = \"murray\";\n\n%% Strlen includes the number of chars in string not including null char %%\n%% Both hello and test %%\ngreeting = malloc(strlen(hello) + strlen(test) + 1);\nstrncpy(greeting, hello, strlen(hello) + strlen(test) + 1);\nstrncat(greeting, test, strlen(test) + 1);\nfree(greeting);\n```\n\nExtra:\n- The difference between new and new[]: \n\t- If type is a non-array type, the name of the function is operator new . If type is an array type, the name of the function is operator new[] ","lastmodified":"2024-03-14T01:23:04.270879219Z","tags":["C","Programming","completed"]},"/notes/G%C3%B6dels-Completeness-Theorem":{"title":"G√∂del's Completeness Theorem","content":"For any collection of first-order statements, every semantic implication of those statements is syntactically provable within first-order logic.\n\nSimply put,\n- all statements which are true in all models are provable\n\nFirst-order logic\n- Includes quantifiers e.g. $\\forall$, $\\exists$, predicates e.g. greater than, equal to and logical connectives e.g. and, or etc.\n- Allows relations between objects, definition of functions","lastmodified":"2024-03-14T01:23:04.270879219Z","tags":["Areas","to-complete"]},"/notes/G%C3%B6dels-Incompleteness-Theorem":{"title":"G√∂del's Incompleteness Theorem","content":"\nSource: [Numberphile on G√∂del's Incompleteness Theorem](https://www.youtube.com/watch?v=O4ndIDcDSGc)\n\nThe simple idea: There might be a conjecture that's true, but there is no way to prove it.\n- Why? There might be a gap between **truth** and **proof**.\n\nFirst, mathematics might not be consistent (i.e. existence of paradoxes). We set down axioms - statements that are self-evidently true for all cases in our mathematical system.\n- Before G√∂del, the initial idea was: We can prove any statement in mathematics if we have a strong enough set of axioms.\n\nG√∂del Coding - Any mathematical statement could be turned into a unique number. A little bit of a simplification but imagine that if a statement can be derived from an axiom, both the numbers will be divisible by each other.\n\nG√∂del's Challenge - Assume a statement cannot be proved from the set of axioms. This statement can be turned into a mathematical equation.\n- Assume that statement is false. This means the statement can be proved from the set of axioms.\n- Contradiction! We assumed this statement can not be proved, but now we have deduced it can be. Since we assume mathematics is consistent, this has to be false.\n\nSo, for any consistent mathematical system, there must be a statement that cannot be proved from the set of axioms.\n\nThe \"regressive\" solution is to add this as an axiom, but that's not really a good solution. I can still find out a statement that's not provable by the axioms.","lastmodified":"2024-03-14T01:23:04.270879219Z","tags":["Areas","to-complete"]},"/notes/Higher-Order-Functions":{"title":"Higher-Order Functions","content":"\nA higher-order function is a function which takes a function as a parameter or which returns the function or both. In JavaScript, an example of this is setTimeout() where one of the parameters is a function we run after some time is passed. \n```\nsetTimeout(() =\u003e {\n\tconsole.log('')\n}, time)\n```","lastmodified":"2024-03-14T01:23:04.270879219Z","tags":["Areas","to-complete"]},"/notes/Image-Feature-Vector":{"title":"Image Feature Vector","content":"A way to abstract information i.e. image, so that it's numerically quantifiable. Simply put, a list of numbers that represents an image. \n\nWhen building an image search engine, the first step is figure out what image descriptor to use. Am I trying to note a change in color, extract an object or differentiate between texture?\n- This will handle the logic needed to represent our image as numbers\n\nAssume we use raw pixel descriptor as our image descriptor.\n- Basically, take all the pixels in an image and without any kind of processing, represent an individual pixel by it's color values (RGB, each channel is 0-255) or intensity (0-255)\n\nA color mean and standard deviation descriptor would find the average and standard deviation of each channel of the image (so, each pixel's RGB values to form 3 numbers)\n- Helps find the spatial distribution of color in an image!\n\nA color histogram descriptor can also help tell us the distribution of colors in an image. If we divide the color space into discrete number of binds and then, count the number of pixels that fall into each bin, we have ourselves a color histogram.","lastmodified":"2024-03-14T01:23:04.270879219Z","tags":["Areas","completed"]},"/notes/Image-Formats-Compression-Comparision":{"title":"Image Formats \u0026 Compression Comparision","content":"Digital graphic files will generally fall into two categories:\n1. Raster graphics are created using a grid of tiny pixels, making them very simple\n2. Vector graphics are creating using detailed paths of points \u0026 lines to render images. \n\nThe simplest format begins with a bitmap, .bmp extension. It's the truest image where it stores every pixel (i.e. Raster file type), it's lossless and uncompressed. \n\nJPEG, Joint Photographic Experts Group, solves the issue of large file sizes and are great for images with gradients. \n- 'Lossy' bitmap format: To maintain small file size, some information of the image is discarded. Saving at maximum quality maximizes as much image quality as possible.\n- JPEG Artefacts are result of an aggressive data compression result or conversion between different formats. This is especially noticeable in images with sharp lines, or sharp contrast between two colours. \n\nResource: [Mathematics behind JPEG](https://cuhkmath.wordpress.com/2012/10/06/mathematics-behind-jpeg/)\nThe Fourier coefficients indicate how the function oscillates. So, if a function is close to a constant value, the Fourier coefficients of that function decay very fast. So, just with the first few terms of the Fourier series, we will be close to the original function. \n\nHow can we use this property to store images efficiently in JPEG format?\n- Calculate the Fourier coefficients of an image (i.e. perform a 2D Fourier Transform on the image to represent in frequency domain).\nIn python, this can be achieved by:\n``` python\nimport numpy as np\nf_transform = np.fft.fft2(image)\n```\n- Store the first few big Fourier coefficients, discard the small, high-frequency coefficients\nIt's also why JPEG does not work well with storing text - there is a big change in background colour and text colour. These are big coefficients with high frequency, and discarding this information leads to JPEG artefacts.\n\nPNG, which contrary to JPEG, they render sharp contrasts better than gradients by being more smarter with how they store image. It's a raster file format, lossless and smaller file size. \n\nHow does it compress images? \nIt compares individual pixels with neighbouring pixels. If they are of the same color, it compresses this information.\n\nSVG, Scalable Vector Graphics, is a vector graphic file which stores the instructions on how to draw. These are impossible for photos, but nice for logos or simpler images.","lastmodified":"2024-03-14T01:23:04.270879219Z","tags":["Areas","completed"]},"/notes/Interrupts-and-System-Calls":{"title":"Interrupts and System Calls","content":"To execute a program, the components for a minimal set are:\n- Main memory\n- System Bus\n- Processor\n\t- Within this, we have a I/O communicating data to us that requires some processing\n\t- Central Processing Unit (with a Control Unit and ALU) communicates with memory unit.\n\n**Processor **\n- Brain of the computer which fetches instructions, decodes them, executes them (a cycle which repeats infinitely)\n- Different steps may be completed in parallel (pipeline) --\u003e ECE 222\n- The largest unit in a processor is the word: \n\t- 32-bit computer -\u003e 32-bit word, 64-bit computer -\u003e 64-bit word\n\n**CPU**\n- CPU instructions are specific to the processor (x86, ARM, RISC, MIFS)\n\t- Some instructions are only available in \"supervisor\" mode and running it in user mode is an error.\n\t- When running our programs, we can't ask to \"close\" the computer or read input from keyboard directly. What if we do the wrong thing, crash the computer in a while loop forever?\n- CPUs have storage locations called registers\n\t- These will store data or instructions. A great analogy is if memory is a bookshelf, these are your pockets - quick access to data\n\t- Management of registers is partially the role of the OS. \n\n**Critical Registers in CPU**\n- Program Counter - address of next instruction. \n\t- The reason we have this is because if statements or for loops, it's not always sequential. We might need to branch back to a previous line. \n- Status Register - Array of bits to indicate flags. For example, if we are in supervisor mode, if there's low power\n- Instruction Register - Instruction most recently fetched, so in decode stage, we can refer to this\n- Stack Pointer - Where the local data is kept. We really care about this because all our local variables are here in memory\n- General Purpose Registers - store data, addresses etc. Basically, pockets to put in data to use later.\n\nHow do we inform the computer of something that just happened? **Interrupts**\n- CPU needs data but it takes a variable amount of time to get that information, while I work on something else.\n\t- Interrupt: Get a notification when data has arrived\n- Polling is separate: Check periodically if the data has arrived\n\nInterrupts are a way to improve processor utilization (as opposed to polling)\n- When an interrupt fires, the CPU might ignore it but usually, we need to handle it.\n\t- When the computer is in sleep mode, we might want to ignore the key interrupt.\n- OS, the goat will store the state of the CPU and whatever the processor is running, handles the interrupt and restores the state.\n\t- If CPU is in the middle of something that can not be interrupted, interrupts will be disabled. \n\n- Source of Interrupts: We can put polling into four categories, based on their origin\n\t- Program - When doing concurrency, this is the most common one.\n\t- Timer - If we want to blink an led at a certain rate, timer will go again\n\t- Input/Output - Moving a mouse, keyboard input etc.\n\t- Hardware Failure - During a power outage, or battery low (not hardware failure but same idea), where the PC will safely shut itself off.\n\nThere can be multiple interrupts in a short period of time. \n- In sequential handling, we finish Interrupt Handler X, and then go to Interrupt Handler Y.\n\t- The best way to think about this is two questions asking a teacher\n- In nested handling, we go to Interrupt Handler X and then go to Interrupt Handler Y, finish it, finish X and go back\n\t- Makes sense if Y is higher priority, think of a teacher answering a student's question (Interrupt Handler X) and a fire alarm starts (Interrupt Handler Y starts with obviously higher priority)\nIn general, priorities are assigned a priority level. If priority level is higher, it will interrupt anything lower than it.\n\nThe OS must store the program state when an interrupt occurs (state being the values of registers). Push them onto the stack and when the interrupt is finished, pop them off the stack, and continue execution.\n\n**Context Switching:** process of saving the state of one program and restoring the state of another, allowing the CPU to efficiently manage multiple tasks.\n**Trap**: software-generated interrupt. Generated by an error (invalid instruction) or user program request\n","lastmodified":"2024-03-14T01:23:04.270879219Z","tags":["Areas","OperatingSystems","to-complete","ece252"]},"/notes/Introduction-to-OS":{"title":"Introduction to OS","content":"Operating System: It sits between hardware and programs. \n**OS as a Resource Manager**, the \"secretary\" of the system\n- Responsible for resource managements and allocation, cause resources (e.g. CPU time, memory) are limited\n- Chooses the winner in the event of conflicting requests\n\n**OS as an Environment Provider**, \n- Allows useful programs to run, while abstracting details of hardware (i.e. Imagine changing how to print Hello World for different hardware builds)\n\n**OS as a Multitasker**,\n- Resources (like Keyboard) are shared between multiple programs, and OS creates/enforces these rules\n\n**Systems Programming**, programs include\n- File Manipulation\n- Communication\n- Processes and Thread Management\nOS will sometimes not allow programs to do things, and instead, we need to ask the OS to do it.\n\n**Concurrency** - A program is said to be concurrent if it can support two or more actions in progress at the same time.\n**Parallelism** - A program is said to run in parallel if it can have two or more actions execute simultaneously\n\nNote, a program with concurrency problem will see the following errors:\n1. Consistently the wrong answer every single time  \n2. Different on consecutive runs with the same input, or  \n3. Correct some of the time but incorrect some of the time\n","lastmodified":"2024-03-14T01:23:04.270879219Z","tags":["#OperatingSystems","Areas","C","to-complete","ece252"]},"/notes/JSON":{"title":"JSON","content":"*JavaScript Object Notation, hierarchical document schema to define objects with many attributes*\n\nBest demonstrated with an example:\n```json\n{\n\t\"fruits\": [\n\t\t{\n\t\t\t\"name\": \"apple\",\n\t\t\t\"colour\": [\"red\"]\n\t\t},\n\t\t{\n\t\t\t\"name\": \"orange\",\n\t\t\t\"colour\": [\"orange\"],\n\t\t\t\"taste\": \"interesting\"\n\t\t}\n\t]\n}\n```","lastmodified":"2024-03-14T01:23:04.270879219Z","tags":["Areas","DataFundamentals","completed"]},"/notes/Multi-threaded-Web-Server":{"title":"Multi-threaded Web Server","content":"**Background**\n- [[Fundamentals of C]]\n- [[Socket Programming]]\n\n","lastmodified":"2024-03-14T01:23:04.270879219Z","tags":["Projects","SocketProgramming","C","to-complete"]},"/notes/Multiple-Linear-Programming":{"title":"Multiple Linear Regression","content":"Statistical technique that uses two or more independent variables to predict the outcome of a dependent variable\n- determine the relative contribution of each independent variable in total variance\n\nEquation of Multiple Linear Regression:\n$y = b_0 + b_1X_1 + b_2X_2 + + b_3X_3 + ... + b_nX_n$\n- $y$ is the dependent variable, $b_0$ is the y-intercept (constant), and $X_n$ is the independent variable (with a slope coefficient)\n\n**Dummy Variables**\nFor categorical variables, how can we represent them in a multiple linear regression equation? We can use dummy variables - **variable that takes values of 0 and 1, where the values indicate the presence or absence of something**. For each level of categorical variable, we assign a dummy variable and use that in our equation.\n\n*Dummy Variable Trap*\n- Attributes that are highly correlated and one variable predicts the others.\n- Occurs with one-hot encoding of categorical data where one dummy variable predicts the other\n- Results in multicollinearity, affecting regression models\n- Solution: remove one dummy variable!\n","lastmodified":"2024-03-14T01:23:04.270879219Z","tags":["Areas","to-complete"]},"/notes/ORC":{"title":"ORC","content":"*Optimized Row Columnar Format, organized into columns that optimize read/write operations for Apache Hive*\n- Apache Hive: data warehouse that has fast data summarization and querying over large datasets\n- Columnar storage format to allow for optimized column-based operations like filtering/aggregation\n- ORC stores data in a series of stripes where each strip is a collection of rows. \n\t- each stripe is further divided into a series of data chunks where each stores data for columns\n\t- also, metadata can be used to quickly read data without scanning entire file\n\t- ORC can store indexes for specific columns, for faster retrieval of specific rows\n\nSimilar to [[Parquet]], [[Avro]]","lastmodified":"2024-03-14T01:23:04.270879219Z","tags":["DataFundamentals","Areas","completed"]},"/notes/Parquet":{"title":"Parquet","content":"*Open-source columnar storage file format used for big data processing*\n- Columnar storage format to allow for optimized column-based operations like filtering/aggregation\n- Data in parquet file is divided into columns, and groups of columns are organized into row groups\n\t- each row group contains a section of data, and group of columns are organized into row groups\n\t- each row group has some data, and columns within a row group are stored together\n- Parquet files contains metadata that define structure of data. The three main metadata that can be found:\n\t- file metadata - high-level information such as schema, row groups etc.\n\t- column metadata - encoding, data types, compression etc\n\t- page-header metadata - data page, dictionary references etc.\n- Dictionary encoding: Compresses repetitive data by replacing those values with short id's that refer to a dictionary of unique values\n- Predicate pushdown: Query Optimization technique that filters data at source before it's read on memory\n\t- By applying filtering conditions early in the read process, only relevant data is loaded into memory\nSimilar to [[ORC]], [[Avro]]\n\nResource:\n- https://learncsdesigns.medium.com/understanding-apache-parquet-d722645cfe74","lastmodified":"2024-03-14T01:23:04.270879219Z","tags":["DataFundamentals","Areas","completed"]},"/notes/Programming-Paradigm":{"title":"Programming Paradigm","content":"\n*Definition:* Methods or set of rules to structure code and solve a problem\n\nThe common types of paradigm:\n- Procedural Programming\n- Logical Programming\n- [[Functional Programming]]\n- Object-oriented Programming","lastmodified":"2024-03-14T01:23:04.270879219Z","tags":["Areas","to-complete"]},"/notes/Projects":{"title":"‚úÖ Projects","content":"[[Multi-threaded Web Server]]\n","lastmodified":"2024-03-14T01:23:04.270879219Z","tags":["Projects","to-complete"]},"/notes/Resources":{"title":"üìö Resources","content":"","lastmodified":"2024-03-14T01:23:04.270879219Z","tags":["Resources","to-complete"]},"/notes/Socket-Programming":{"title":"Socket Programming","content":"- **Sockets** allow for Inter-Process Communication (IPC) between two different processes on same/different machines. \n- **Socket Programming** is connecting two nodes on a network so they can communicate.\n\t- **Server** socket will listen on a port at an IP, and service requests it receives from clients\n\t- **Client** socket reaches out to make a connection, and sends requests. \n![](https://media.geeksforgeeks.org/wp-content/uploads/20220330131350/StatediagramforserverandclientmodelofSocketdrawio2-448x660.png)\n\n- `socket()` involves creating the socket, `bind()` will binds the newly created socket to an address and port\n- If the server socket is not put into passive mode with `listen()`, it will lead to an error\n\t- A server will queue certain number of clients, before returning `ECONNREFUSED`\n- `accept()` extracts first request in queue and establishes connection\n\nThe above model assumes server handles one client at a time. What about multiple clients?\n- Option 1: Multi-threading but it's not a good idea\n\t- Unpredictable results with threading\n\t- Overhead switching of context\n\t- Deadlocks can occur \n\nReference: \n- https://www.geeksforgeeks.org/socket-programming-cc/\n- https://www.geeksforgeeks.org/socket-programming-in-cc-handling-multiple-clients-on-server-without-multi-threading/\n","lastmodified":"2024-03-14T01:23:04.270879219Z","tags":["SocketProgramming","C","to-complete"]},"/notes/XML":{"title":"XML","content":"*Markup language that provides rules to define data*\n- tags in XML are markup symbols to define data\n\t- allows for data coding to get information flows across systems\n- XML schema (XSD): document that describes rules on structure of XML file\n- XML parser: process or read XML files to extract data, check syntax or validate against schema\n- Note: While similar in appearances, this is different from HTML\n\t- ability to define custom tags, as opposed to pre-defined HTML tags\n\t- HTML is for content, XML stores and transports data\n\t- XML is case-sensitive, HTML is not.","lastmodified":"2024-03-14T01:23:04.270879219Z","tags":["DataFundamentals","Areas","completed"]},"/notes/Zettel":{"title":"Zettel","content":"Essentially, a single note on one particular topic! The anatomy of a zettel looks like:\n- Unique Identifier: an unambiguous address\n\t- This is mandatory! Why? Cause it allows for a unique way to identify each note. There are some ways we can go about achieving this!\n\t- Luhmann-ID\n\t\t- It's a hierarchy and sort of similar to how indexing with bullet points work. You have Note 1 and Note 2, and a note between this would be called Note 1a\n\t- Time-based ID + Arbit. unique string\n\t\t- This is what i'm going to use since Obsidian has support for this. Note, each [[Zettel]] will end up having it's own unique string i.e. \"title\" anyways.\n- Body/Content: the actual content\n- Footer/References: source of knowledge or personal thoughts\n\t- Also, consider [[../Collector's Fallacy]]\nWhen adding links to other content, there needs to be an explanation as to why it is there! If not, this is not knowledge but information!\n- This was an interesting point mentioned somewhere in: https://zettelkasten.de/introduction/#luhmann-s-zettelkasten. How do we categorize text as \"knowledge\" or \"information\"? Even better, how do I know what I am writing is knowledge (very critical for zettelkasten)!\n\t- Well, information is \"dead\" - it needs processing for it to give any relevant information. If I write out all the calories I consumed in a day, that's just information on by daily eating habits. Knowledge would be to dissect this and make some inferences. \n\nThere are a few things to consider in terms of actual contents: Writing the note, expanding the note, and when has it become too inflated. \n- Keep a draft outline which involves bulletting ideas \n- When expanding a note: add items to a collection, add references to back up a point or write a text to incorporate new knowledge. \n- There's no universal guideline to know when it's too big, but re-reading notes and considering if it can be broken down further.\n\nA great read: [Object Tags vs. Topic Tags](https://zettelkasten.de/posts/object-tags-vs-topic-tags/)","lastmodified":"2024-03-14T01:23:04.270879219Z","tags":["NoteTaking","ZettelkastenGuide","Areas","completed"]},"/notes/Zettelkasten":{"title":"Zettelkasten","content":"Note: I'm referencing [zettelkasten.de](https://zettelkasten.de/posts/overview/#the-introduction-to-the-zettelkasten-method) to understand how to incorporate this into my daily note-taking!\n\nContrary to what a \"[[Zettel]]\" should be, i.e. adhere to principle of atomicity and be \"hyper-textual\", I am not placing any such constraints here. While I will try to achieve this, my main goal is to familiarize myself with how it works. \n\nIn this system, it is recommended that there are no categories as explained in this article: [#Why Categories for Your Note Archive are a Bad Idea](https://zettelkasten.de/posts/no-categories/)\n\nHowever, this isn't the most suitable for my style. I need a way to differentiate my personal items from work or school. So, let's keep them really general! For now, internally, the four major categories are:\n- **PERSONAL**: Related to health, finance, personal logs etc\n- **WORK**: Related to internships, resumes, etc\n- **STUDY**: Related to true knowledge items, things I'm learning currently\nI will try my best to avoid subcategories, but I can see situations where it's better to have order over an organic structure.\n\n\u003e [!tip] When starting out, ask yourself:\n\u003e  **Is your Zettelkasten designed for a single writing project or topic, or do you want to map all you know with this tool?**\n\nI want to map everything I know! I want to create a place where I can write about everything I'm learning and connect it to other concepts I've learned. This ecosystem will benefit from overview notes as gentle intros to a topic, similar to this note.ZettelkastenTools\n","lastmodified":"2024-03-14T01:23:04.270879219Z","tags":["NoteTaking","ZettelkastenGuide","Areas","completed"]}}