{"/":{"title":"Prachee Nanda","content":"\nHi there ðŸ‘‹! Welcome to my digital garden, a collection of notes on topics that have captured my interest and curiosity. Inspired by the Zettelkasten approach, my aim is to expand my knowledge and discover new insights. \n\nThis notebook will keep on changing and improving over time, so don't expect it to be perfect yet. Some pages might still be a work in progress.","lastmodified":"2023-04-29T17:51:47.434377889Z","tags":[]},"/private/personal/Practical-Text-Classification-With-Python-and-Keras":{"title":"Practical Text Classification With Python and Keras","content":"Link: https://realpython.com/python-keras-text-classification/\n\nApplication: Sentiment analysis, Text classification (i.e. detection of spam), auto tagging of customer queries, categorization of text into defined topics.\n- My goal is to figure out if I can figure out what soft/hard skills are needed from a job description.\n\nSet up a python virtual environment: [[private/personal/Setup Python Virtual Environment]]\n\n**Choosing a Data Set**\nRepository for ML Data Sets: https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences\n- Each review is marked with a score of 0 for negative sentiment, score of 1 for positive sentiment\n\nHow to predict the sentiment of the source:\n- Count the freq. of each word in each sentence + tie this count back to the entire set of words\n- Create a corpus (take the data and create a vocabulary from all words)\n\t- Vocabulary is a list of words from the text, with each word having an index\n- This allows us to create a vector for a sentence where we count how many times a word appears in a sentence. Resulting vector is also called a feature vector (the dimension is a numeric or categorical feature, i.e. count of word in a vocabulary)\n- Vocabulary serves as an index of each word and allows for the count of each word in a sentence to be represented by a vector \n- This new vector represents occurence of each word in the sentences based on the vocabulary\nThis is considered as a Bag of Words model.\n\n**Define a Baseline model**\nSplit the data into a training and test set which will let me evacuate the accuracy, and check if the model generalizes well. This is to check if the model is **overfitting**.\n\nOverfitting - the model is trained too well on training data (model is just memorizing the data). \n\n```\nsklearn.model_selection.train_test_split(*arrays, **options) -\u003e list\n```\nOptions are the optional keywords to get a desired behavior:\n- train_size, test_size - defines the size of training set and test set\n- random_state - controls randomization during splitting\n- shuffle - determines whether to shuffle dataset after splitting\n- stratify - https://en.wikipedia.org/wiki/Stratified_sampling\n\nhttps://docs.scipy.org/doc/scipy/reference/sparse.html\n- Data type optimized for matrices with only a few non-zero elements (reduces memory loads)\n- tokenization - separates the sentences into a set of tokens (removes punctuation and special character)\n\nClassification model we use is logistic regression.\n\n\" You start by having a layer of input neurons where you feed in your feature vectors and the values are then feeded forward to a hidden layer. At each connection, you are feeding the value forward, while the value is multiplied by a weight and a bias is added to the value. This happens at every connection and at the end you reach an output layer with one or more output nodes. \"\n\n\n\n\n","lastmodified":"2023-04-29T17:51:47.434377889Z","tags":[]},"/private/personal/Setup-Python-Virtual-Environment":{"title":"Setup Python Virtual Environment","content":"Install virtual environment using venv\n``` bash\npip install virtualenv\n```\n\nCreate a virtual environment in folder:\n```\npython3.11 -m venv env\n```\n\nTo activate and then, deactivate the virtual environment\n```bash\nsource env/bin/activate\n~ deactivate\n```\n\nTo check list of packages installed in the virtual environment:\n```bash\npip list\n```\n\nThis will generate a text file listing project dependencies:\n```\npip freeze \u003e requirements.txt\n```\n\n```bash\n ~ pip install -r requirements.txt\n```\n\n","lastmodified":"2023-04-29T17:51:47.434377889Z","tags":[]}}